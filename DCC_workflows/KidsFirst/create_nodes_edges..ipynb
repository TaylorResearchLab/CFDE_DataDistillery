{
  "metadata": {
    "name": "create_nodes_edges",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Run this notebook after running get_variants and producing the chromosome files in merged_snps/\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport pandas as pd\nimport numpy as np\n\ndef fill_missing_cols(df):\n    if \u0027node_id\u0027 not in df.columns:\n        raise ValueError(\u0027Must have at least a \"node_id\" column.\u0027)\n        \n    all_cols \u003d set([ \u0027node_label\u0027, \u0027node_synonyms\u0027, \u0027node_dbxrefs\u0027,\n            \u0027node_definition\u0027,\u0027node_namespace\u0027,\u0027value\u0027,\u0027lowerbound\u0027,\u0027upperbound\u0027,\u0027unit\u0027])\n   \n    missing_cols \u003d list(all_cols - set(df.columns))\n    nan_cols_df \u003d pd.DataFrame(np.full([len(df), len(missing_cols)], np.nan),columns\u003dmissing_cols)\n    nan_cols_df.index \u003d df.index\n    return pd.concat([df,nan_cols_df],axis\u003d1)\n    "
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\ncd ~/.sevenbridges/\nif [[ -e \u0027credentials\u0027 ]]; then mv credentials credentials.bak; fi\ncat \u003c\u003c EOF \u003e credentials\n[default]\napi_endpoint \u003d https://cavatica-api.sbgenomics.com/v2\nauth_token   \u003d c05edbf9ffe041479f063666e23f675f\nEOF\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\ncd ~\nif ! [[ -x \u0027sbfs\u0027 ]]; then curl https://igor.sbgenomics.com/downloads/sbfs/linux-amd64/sbfs -O; chmod 755 sbfs; fi"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\ncd ~\n! [[ -x \u0027cavatica\u0027 ]] \u0026\u0026 mkdir ~/cavatica\n[[ \"$(ls -A ~/cavatica)\" ]] || ~/sbfs mount ~/cavatica\necho \u0027Wait until mounting is done ...\u0027\nwhile [[ -e ~/cavatica/mount_status ]]; do sleep 1; done\nls -l ~/cavatica/projects/"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\naws s3 ls s3://kf-strides-variant-parquet-prd/notebooks/5175e6e3-c3d7-4c19-b51f-6f1ea4dd3700/DataDistillery/merged_snps/"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#merged_all \u003d spark.read.parquet(\u0027s3a://kf-strides-variant-parquet-prd/notebooks/5175e6e3-c3d7-4c19-b51f-6f1ea4dd3700/DataDistillery/merged_snps/*.parquet\u0027)\n#print(merged_all.count())\n#merged_all.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nCHD_merged_genes_inner \u003d spark.read.parquet(\u0027s3a://kf-strides-variant-parquet-prd/notebooks/5175e6e3-c3d7-4c19-b51f-6f1ea4dd3700/DataDistillery/CHD_merged_genes_inner.parquet\u0027)\nprint(CHD_merged_genes_inner.count())\nCHD_merged_genes_inner.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nCHD_merged_genes_inner \u003d CHD_merged_genes_inner.drop_duplicates()\nCHD_merged_genes_inner.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# load in gene symbol to hgnc code mappings\nhgnc_master \u003d pd.read_csv(\u0027~/cavatica/projects/taylordm/taylor-urbs-r03-kf-cardiac/hgnc_master.txt\u0027,sep\u003d\u0027\\t\u0027)\nhgnc_master_merge_cols \u003d hgnc_master[[\u0027hgnc_id\u0027,\u0027symbol\u0027]]"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#CHD_merged_genes_inner.show()\n\ngb \u003d CHD_merged_genes_inner.groupBy(\u0027symbol\u0027).count().orderBy(\u0027count\u0027, ascending\u003dFalse).toPandas()\ngb"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#merged_all \u003d spark.read.parquet(f\"s3a://kf-strides-variant-parquet-prd/notebooks/5175e6e3-c3d7-4c19-b51f-6f1ea4dd3700/DataDistillery/CHD_merged_genes.parquet\")\n#gb \u003d merged_all.groupBy(\u0027node_id\u0027).count().orderBy(\u0027count\u0027, ascending\u003dFalse).toPandas()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#merged_df[merged_df[\u0027ensembl_gene_id\u0027]!\u003dNone]\n#merged_df[\u0027ensembl_gene_id\u0027] \u003d\n#merged_df[[True if type(i)\u003d\u003dstr else False for i in merged_df[\u0027ensembl_gene_id\u0027] ]]\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#merged_all_genes \u003d spark.read.parquet(f\"s3a://kf-strides-variant-parquet-prd/notebooks/5175e6e3-c3d7-4c19-b51f-6f1ea4dd3700/DataDistillery/CHD_merged_genes.parquet\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# format code nodes (for KFVARBINS nodes, which are connected to CHLO nodes)\n\n#gb[\u0027node_id\u0027] \u003d [\u0027CHLO \u0027 + i.replace(\u0027:\u0027,\u0027.\u0027) for i in gb[\u0027node_id\u0027]]\n#gb[\u0027KFVARBIN_CodeID\u0027] \u003d [\u0027KFVARBIN \u0027+i.replace(\u0027:\u0027,\u0027.\u0027).split(\u0027 \u0027)[-1] for i in gb[\u0027node_id\u0027]]\n#gb.head(5)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ngb \u003d pd.merge(gb,hgnc_master_merge_cols)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ngb"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# format code nodes for KFGENEBINS nodes, which are connected to HGNC nodes)\n\ngb[\u0027node_id\u0027] \u003d [i.replace(\u0027:\u0027,\u0027-\u0027)+\u0027-variant-count\u0027 for i in gb[\u0027symbol\u0027]]        #[\u0027CHLO \u0027 + i.replace(\u0027:\u0027,\u0027.\u0027) for i in gb[\u0027node_id\u0027]]\ngb[\u0027KFGENEBIN_CodeID\u0027] \u003d [\u0027KFGENEBIN \u0027+i for i in gb[\u0027node_id\u0027]]\ngb.head(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Every bin will show up at least once?\n#gb \u003d gb[gb[\u0027count\u0027] \u003e 1]\n#print(len(gb))"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnodes \u003d gb[[\u0027KFGENEBIN_CodeID\u0027,\u0027count\u0027]].rename(columns\u003d{\u0027KFGENEBIN_CodeID\u0027:\u0027node_id\u0027,\u0027count\u0027:\u0027value\u0027})\nnodes \u003d fill_missing_cols(nodes)"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#name_id_df \u003d spark.table(\u0027studies\u0027).select([\u0027kf_id\u0027,\u0027short_name\u0027,\u0027short_code\u0027])\n#name_id_df.toPandas().to_csv(\u0027~/cavatica/projects/taylordm/taylor-urbs-r03-kf-cardiac/DataDistillery/KF_study_id_name_mapping.txt\u0027,sep\u003d\u0027\\t\u0027,index\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ngb[\u0027HGNC_CodeID\u0027] \u003d [\u0027HGNC \u0027 + i for i in gb[\u0027hgnc_id\u0027]]"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Define edges\ngb[\u0027predicate\u0027] \u003d \u0027gene_has_variants\u0027\nedges \u003d gb[[\u0027KFGENEBIN_CodeID\u0027,\u0027predicate\u0027,\u0027HGNC_CodeID\u0027]]\nedges.columns \u003d [\u0027subject\u0027,\u0027predicate\u0027,\u0027object\u0027]\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n\n# Define relationships to cohort \ngb[\u0027KFCOHORT_CodeID\u0027] \u003d \u0027KFCOHORT SD-PREASA7S\u0027  \ngb[\u0027KFCOHORT_node_label\u0027] \u003d \u0027Kids First: Congenital Heart Defects\u0027\ngb[\u0027cohort_predicate\u0027] \u003d \u0027belongs_to_cohort\u0027\n\nedges_cohort \u003d gb[[\u0027KFGENEBIN_CodeID\u0027,\u0027cohort_predicate\u0027,\u0027KFCOHORT_CodeID\u0027]]\nedges_cohort.columns \u003d [\u0027subject\u0027,\u0027predicate\u0027,\u0027object\u0027]\n\nedges_all \u003d pd.concat([edges,edges_cohort])\n"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom collections import Counter\nCounter([i.split(\u0027 \u0027)[0] for i in edges_all[\u0027subject\u0027]])"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nCounter([i.split(\u0027 \u0027)[0] for i in edges_all[\u0027object\u0027]])"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nedges_all \u003d edges_all.drop_duplicates().reset_index(drop\u003dTrue)\nedges_all.to_pickle(\u0027~/cavatica/projects/taylordm/taylor-urbs-r03-kf-cardiac/DataDistillery/OWLNETS_edgelist.pickle\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nedges_all.to_csv(\u0027~/cavatica/projects/taylordm/taylor-urbs-r03-kf-cardiac/DataDistillery/OWLNETS_edgelist.txt\u0027,sep\u003d\u0027\\t\u0027,index\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnodes_cohort \u003d fill_missing_cols(gb[[\u0027KFCOHORT_CodeID\u0027,\u0027KFCOHORT_node_label\u0027]].rename(columns\u003d{\u0027KFCOHORT_CodeID\u0027:\u0027node_id\u0027,\n                                                                                                \u0027KFCOHORT_node_label\u0027:\u0027node_label\u0027}).drop_duplicates())\nnodes_cohort                                                                                                "
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnodes[\u0027value\u0027] \u003d nodes[\u0027value\u0027].astype(int)"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnodes_all \u003d pd.concat([nodes,nodes_cohort]).drop_duplicates().reset_index(drop\u003dTrue)\nnodes_all \u003d nodes_all.drop_duplicates().reset_index(drop\u003dTrue)"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nCounter([i.split(\u0027 \u0027)[0] for i in nodes_all[\u0027node_id\u0027]])"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nnodes_all.to_csv(\u0027~/cavatica/projects/taylordm/taylor-urbs-r03-kf-cardiac/DataDistillery/OWLNETS_node_metadata.txt\u0027,sep\u003d\u0027\\t\u0027,index\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnodes_all #.toPandas()"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnodes_all"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}